#############################################
# create necessary users for hadoop
#############################################
useradd lgx-hadoop
echo "lgx-hadoop" | passwd lgx-hadoop --stdin

#############################################
# ssh setups
#############################################
su lgx-hadoop <<EOF
   if [[ -f ~/.ssh/id_rsa ]]; then
      rm -f ~/.ssh/id_rsa
   fi

   if [[ -f ~/.ssh/id_rsa.pub ]]; then
      rm -f ~/.ssh/id_rsa.pub
   fi

   ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa

   if [[ ! -f ~/.ssh/authorized_keys ]]; then
      touch ~/.ssh/authorized_keys
   fi

   cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
   chmod 0600 ~/.ssh/authorized_keys
   exit
EOF

###############################################
# install jdk
###############################################
yum install -y java-devel java
### check java is installed

###############################################
# install hadoop
###############################################
cd /tmp
rm -f lgx-hadoop.tar.gz 
wget -O lgx-hadoop.tar.gz http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz

rm -rf lgx-hadoop
mkdir -p lgx-hadoop
tar -zxvf lgx-hadoop.tar.gz -C lgx-hadoop --strip-components 1

rm -rf /usr/local/lgx-hadoop
mv lgx-hadoop /usr/local

sed -i "/HADOOP/d" ~/.bashrc
sed -i "/YARN_HOME/d" ~/.bashrc
cat >> ~/.bashrc <<EOF

###########################################################
#		  GENERATED BY SCRIPTS                    #
###########################################################
export HADOOP_HOME=/usr/local/lgx-hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME

export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_INSTALL=$HADOOP_HOME

###########################################################
#		         END				  #
###########################################################

EOF

# setup hadoop configure files
cd /usr/local/lgx-hadoop/etc/hadoop

## set JAVA_HOME env
## todo:
jdk_home=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.212.b04-0.el7_6.x86_64/
if [[ ! -f hadoop-env.sh.bak ]]; then
    cp hadoop-env.sh hadoop-env.sh.bak
fi
sed -i "s@# export JAVA_HOME=@export JAVA_HOME=${jdk_home}@g" hadoop-env.sh

## setup core-site.xml
if [[ ! -f core-site.xml.bak ]]; then
    cp core-site.xml core-site.xml.bak
fi
cp core-site.xml core-site.xml.bak
sed -i '/configuration>/d' core-site.xml
cat >> core-site.xml <<EOF

<!--          GENERATED BY SCRIPTS          -->

<configuration>
    <property>
	<name>fs.default.name</name>
	<value>hdfs://localhost:9000</value>
    </property>
</configuration>

<!--                  END                  -->

EOF

## setup hdfs-site.xml
mkdir -p /usr/local/lgx-hadoop/hadoopinfra
chown -R lgx-hadoop /usr/local/lgx-hadoop/hadoopinfra
chgrp -R lgx-hadoop /usr/local/lgx-hadoop/hadoopinfra

if [[ ! -f hdfs-site.xml.bak ]]; then
    cp hdfs-site.xml hdfs-site.xml.bak
fi
sed -i '/configuration>/d' hdfs-site.xml
cat >> hdfs-site.xml <<EOF

<!--          GENERATED BY SCRIPTS          -->

<configuration>
    <property>
        <name>dfs.replication</name>
	<value>1</value>
    </property>

    <property>
	<name>dfs.name.dir</name>
	<value>file:///usr/local/lgx-hadoop/hadoopinfra/hdfs/namenode</value>
    </property>

    <property>
	<name>dfs.data.dir</name>
	<value>file:///usr/local/lgx-hadoop/hadoopinfra/hdfs/datanode</value>
    </property>
</configuration>

<!--                  END                  -->

EOF

## setup yarn-site.xml
if [[ ! -f yarn-site.xml.bak ]]; then
    cp yarn-site.xml yarn-site.xml.bak
fi
sed -i '/configuration>/d' yarn-site.xml
cat >> yarn-site.xml <<EOF

<!--          GENERATED BY SCRIPTS          -->

<configuration>
    <property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
    </property>
</configuration>

<!--                  END                  -->

EOF

## setup mapred-site.xml
if [[ ! -f mapred-site.xml.bak ]]; then
    cp mapred-site.xml mapred-site.xml.bak
fi
sed -i '/configuration>/d' mapred-site.xml
cat >> mapred-site.xml <<EOF

<!--          GENERATED BY SCRIPTS          -->

<configuration>
    <property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
    </property>
</configuration>

<!--                  END                  -->

EOF

###############################################
## prerequsites before running hadoop
###############################################
rm -rf /usr/local/lgx-hadoop/logs
mkdir -p /usr/local/lgx-hadoop/logs
chown -R lgx-hadoop /usr/local/lgx-hadoop/logs
chgrp -R lgx-hadoop /usr/local/lgx-hadoop/logs

su lgx-hadoop <<EOF
   /usr/local/lgx-hadoop/bin/hdfs namenode -format
   /usr/local/lgx-hadoop/sbin/start-dfs.sh
   /usr/local/lgx-hadoop/sbin/start-yarn.sh

EOF
